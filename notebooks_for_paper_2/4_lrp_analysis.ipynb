{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, loading, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point, MultiPolygon\n",
    "\n",
    "from sklearn import linear_model\n",
    "import pysumma.plotting as psp\n",
    "import pysumma.utils as psu\n",
    "import pysumma.evaluation as pse\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from sknetwork.visualization import svg_graph, svg_digraph, svg_bigraph\n",
    "from sknetwork.embedding import *\n",
    "from sknetwork.clustering import Louvain\n",
    "\n",
    "from scipy import sparse\n",
    "from IPython.display import SVG\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import shap\n",
    "import innvestigate\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "mpl.style.use('seaborn-talk')\n",
    "sns.set_context('talk')\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "K.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../new_models/all_var_dense_dropout.h5')\n",
    "sim_sites = os.listdir('../sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ds    = {s: xr.open_dataset(f'../data_for_paper_2/{s}_data.nc').load() for s in tqdm(sim_sites)}\n",
    "site_r_qle = {s: xr.open_dataset(f'../data_for_paper_2/{s}_lrp_qle.nc').load() for s in tqdm(sim_sites)}\n",
    "site_r_qh  = {s: xr.open_dataset(f'../data_for_paper_2/{s}_lrp_qh.nc').load() for s in tqdm(sim_sites)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_attrs = gpd.GeoDataFrame.from_file('../data_for_paper_2/site_attrs.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_attrs.index = site_attrs['Site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_strings = ['airtemp',       # 0\n",
    "                   'relhum',        # 1\n",
    "                   'swradatm',      # 2\n",
    "                   'surf_sm',       # 3\n",
    "                   'lai',           # 4\n",
    "                   'vegtype',       # 5\n",
    "              ]           \n",
    "\n",
    "var_to_color = {\n",
    "    'swradatm': '#4363d8',\n",
    "    'airtemp': '#e6194B',\n",
    "    'relhum': '#f58231',\n",
    "    'surf_sm': '#911eb4',\n",
    "    'transpirable': '#9A6324',\n",
    "    'vegtype': '#469990',\n",
    "    'soiltype': 'goldenrod',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relhum(T, p, sh):\n",
    "    T0 = 273.16\n",
    "    return sh * (0.263*p)  / np.exp((17.67*(T-T0))/(T-29.65))\n",
    "\n",
    "def L_vap(T):\n",
    "    # J / g\n",
    "    C = T - 273.16\n",
    "    return 2500.8 - (2.36 * C) + (0.0016 * C**2) - (0.00006 * C**3)\n",
    "\n",
    "def Qle_to_ET(Q, T):\n",
    "    g_per_kg = 1e3\n",
    "    return (1 / (g_per_kg * L_vap(T))) * Q\n",
    "\n",
    "def calc_pet(tmin, tmax, tmean, rad, rad_mult=1):\n",
    "    return 0.0023 * (tmean + 17.8) * (tmax - tmin) ** 0.5 * 0.408 * (rad * rad_mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_nn(ds, use_mask=True):\n",
    "    airtemp   = (((ds['airtemp'].values / 27.315) - 10) / 2) + 0.5\n",
    "    swradatm  = (ds['SWRadAtm'].values / 1000) \n",
    "    mask      = ds['gap_filled'].values\n",
    "    relhumid  = calc_relhum(ds['airtemp'].values, ds['airpres'].values, ds['spechum']) / 100\n",
    "    relhumid[relhumid<0] = 0\n",
    "    lai = ds['scalarLAI'].values / 12\n",
    "    try:\n",
    "        canwidth = (ds['heightCanopyTop']).values / 20\n",
    "    except:\n",
    "        canwidth = 1/(lai + 0.001)\n",
    "    vegtype = ds['vegTypeIndex'].values[()] * np.ones_like(mask) / 12\n",
    "    surf_sm = ds['surf_sm'].values\n",
    "\n",
    "    train_input = np.vstack([airtemp,       # 0\n",
    "                             relhumid,      # 1\n",
    "                             swradatm,      # 2\n",
    "                             surf_sm,       # 3\n",
    "                             lai * canwidth, # 4\n",
    "                             vegtype,       # 5\n",
    "                            ]).T \n",
    "    train_output = np.vstack([ds['Qle_cor'].values / 500,\n",
    "                              ds['Qh_cor'].values / 500,]).T\n",
    "    \n",
    "    if use_mask:\n",
    "        train_input = train_input[mask == 0]\n",
    "        train_output = train_output[mask == 0]    \n",
    "    return train_input.astype(np.float32), train_output.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_to_ds(r, timedim, feature_strings=feature_strings):\n",
    "    feature_das = []\n",
    "    for i, feature in enumerate(feature_strings):\n",
    "            r_feat = r[:, i]\n",
    "            feature_das.append(xr.DataArray(r_feat, coords={'time': timedim}, dims=['time'], name=feature))\n",
    "    r_ds = xr.merge(feature_das) \n",
    "    in_sum = np.sum(r)\n",
    "    out_sum = np.sum(r_ds.sum().to_array())\n",
    "    return r_ds\n",
    "\n",
    "def analyze_model(new_input, time_dim, analyzer):\n",
    "    \n",
    "    r_qle = analyzer.analyze(new_input, neuron_selection=0)\n",
    "    r_qh = analyzer.analyze(new_input, neuron_selection=1)\n",
    "    \n",
    "    feature_strings = ['airtemp', 'relhum', 'swradatm', 'surf_sm', 'lai', 'vegtype']\n",
    "    r_qle_ds = lrp_to_ds(r_qle, time_dim, feature_strings)\n",
    "    r_qh_ds = lrp_to_ds(r_qh, time_dim, feature_strings)\n",
    "    return r_qle_ds, r_qh_ds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xargmax(ds, var='SWRadAtm', dim=None):\n",
    "    return ds.isel(**{dim: ds[var].argmax(dim)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "site = 'US-Whs'\n",
    "site = 'CH-Fru'\n",
    "vars_of_interest = ['airtemp', 'relhum', 'SWRadAtm', 'LWRadAtm', 'surf_sm', 'scalarLAI', 'pptrate',#'heightCanopyTop', \n",
    "                    'scalarLatHeatTotal', 'scalarSenHeatTotal', 'Qle_cor', 'Qh_cor', 'time', 'day', 'theta_sat', 'fieldCapacity', 'critSoilWilting']\n",
    "ds = site_ds[site][vars_of_interest]\n",
    "max_ds = ds.groupby(ds['day']).apply(xargmax, dim='time')\n",
    "max_ds['day'] = max_ds['time']\n",
    "max_ds = max_ds.drop('time').rename({'day': 'time'})\n",
    "max_ds['surf_sm'] = max_ds['surf_sm'] * (max_ds['theta_sat'] - max_ds['fieldCapacity']) + max_ds['fieldCapacity']\n",
    "max_r_qle = site_r_qle[site].sel(time=max_ds['time'])\n",
    "max_r_qh = site_r_qh[site].sel(time=max_ds['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal=True\n",
    "if horizontal:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 8), sharex=True)\n",
    "else:\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(8, 15), sharex=True)\n",
    "    axes = axes.T\n",
    "(max_ds['SWRadAtm']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 0], color='dimgrey', label='Input to NNLRP')\n",
    "max_r_qle['swradatm'].groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1, 0], label=r'Relevance to latent Heat')\n",
    "max_r_qh['swradatm'].groupby(max_r_qh['time'].dt.dayofyear).mean().plot(ax=axes[1, 0], label=r'Relevance to sensible heat')\n",
    "axes[0, 0].set_ylabel(r'Shortwave ($W/m^2$)')\n",
    "axes[1, 0].set_ylabel(r'$R_{shortwave}$')\n",
    "axes[0, 0].set_xlabel('')\n",
    "axes[1, 0].set_xlabel('')\n",
    "\n",
    "(max_ds['airtemp']-273.16).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 1], color='dimgrey')\n",
    "max_r_qle['airtemp'].groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1,1], label=r'$R_{T\\rightarrow Q_{le}}$')\n",
    "max_r_qh['airtemp'].groupby(max_r_qh['time'].dt.dayofyear).mean().plot(ax=axes[1,1], label=r'$R_{T\\rightarrow Q_{h}}$')\n",
    "axes[0, 1].set_ylabel(r'Temperature ($^{\\circ}C$)')\n",
    "axes[1, 1].set_ylabel(r'$R_{temperature}$')\n",
    "axes[0, 1].set_xlabel('')\n",
    "axes[1, 1].set_xlabel('')\n",
    "\n",
    "(max_ds['relhum']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 2], color='dimgrey')\n",
    "max_r_qle['relhum'].groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1,2], label=r'$R_{T\\rightarrow Q_{le}}$')\n",
    "max_r_qh['relhum'].groupby(max_r_qh['time'].dt.dayofyear).mean().plot(ax=axes[1,2], label=r'$R_{T\\rightarrow Q_{h}}$')\n",
    "axes[0, 2].set_ylabel(r'Rel. Humidity (%)')\n",
    "axes[1, 2].set_ylabel(r'$R_{humidity}$')\n",
    "axes[0, 2].set_xlabel('')\n",
    "axes[1, 2].set_xlabel('')\n",
    "\n",
    "(max_ds['surf_sm']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 3], color='dimgrey')\n",
    "max_r_qle['surf_sm'].groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1,3], label=r'$R_{T\\rightarrow Q_{le}}$')\n",
    "max_r_qh['surf_sm'].groupby(max_r_qh['time'].dt.dayofyear).mean().plot(ax=axes[1,3], label=r'$R_{T\\rightarrow Q_{h}}$')\n",
    "axes[0, 3].set_ylabel('Soil saturation (frac)')\n",
    "axes[1, 3].set_ylabel(r'$R_{moisture}$')\n",
    "axes[0, 3].set_xlabel('')\n",
    "axes[1, 3].set_xlabel('')\n",
    "\n",
    "(max_ds['Qle_cor']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 4], color='black', label='Observed')\n",
    "(max_ds['scalarLatHeatTotal']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[0, 4], color='crimson', label='Simulated')\n",
    "axes[0, 4].set_ylabel(r'Latent heat ($W/m^2$)')\n",
    "\n",
    "\n",
    "(max_ds['Qh_cor']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1, 4], color='black', label='Observed')\n",
    "(max_ds['scalarSenHeatTotal']).groupby(max_r_qle['time'].dt.dayofyear).mean().plot(ax=axes[1, 4], color='crimson', label='Simulated')\n",
    "axes[1, 4].set_ylabel(r'Sensible heat ($W/m^2$)')\n",
    "axes[0, 4].set_xlabel('')\n",
    "axes[1, 4].set_xlabel('')\n",
    "#axes[1, 4].set_ylim([0, 600])\n",
    "#axes[0, 4].set_ylim([0, 600])\n",
    "\n",
    "doy_idx = [32, 92, 152, 213, 274, 335]\n",
    "doy_lab = ['Feb', 'Apr', 'Jun', 'Aug', 'Oct', 'Dec']\n",
    "axes[0, 4].set_xticks(doy_idx)\n",
    "axes[0, 4].set_xticklabels(doy_lab, rotation=90)\n",
    "axes[1, 4].set_xticks(doy_idx)\n",
    "axes[1, 4].set_xticklabels(doy_lab, rotation=90)\n",
    "axes[1, 4].set_xlim([1, 365])\n",
    "if horizontal:\n",
    "    axes[1, 3].set_xticklabels(doy_lab, rotation=90)\n",
    "    axes[1, 3].set_xlim([1, 365])\n",
    "    axes[1, 2].set_xticklabels(doy_lab, rotation=90)\n",
    "    axes[1, 2].set_xlim([1, 365])\n",
    "    axes[1, 1].set_xticklabels(doy_lab, rotation=90)\n",
    "    axes[1, 1].set_xlim([1, 365])\n",
    "    axes[1, 0].set_xticklabels(doy_lab, rotation=90)\n",
    "    axes[1, 0].set_xlim([1, 365])\n",
    "\n",
    "axes[1, 0].axhline(0, color='black', linestyle='--')\n",
    "axes[1, 1].axhline(0, color='black', linestyle='--')\n",
    "axes[1, 2].axhline(0, color='black', linestyle='--')\n",
    "axes[1, 3].axhline(0, color='black', linestyle='--')\n",
    "if horizontal:\n",
    "    plt.tight_layout()\n",
    "    axes[1, 0].legend(bbox_to_anchor=(2, -0.3))\n",
    "    axes[0, 0].legend(bbox_to_anchor=(1.3, 1.2))\n",
    "    axes[1, 4].legend(bbox_to_anchor=(1, -0.3))\n",
    "else:\n",
    "    plt.tight_layout()\n",
    "    axes[1, 0].legend(bbox_to_anchor=(.975, 1.3),ncol=2)\n",
    "    axes[1, 4].legend(bbox_to_anchor=(1, -0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "r_sm_rh_qle = []\n",
    "r_sm_rh_qh = []\n",
    "for site in tqdm(sim_sites):\n",
    "    p = site_attrs.loc[site]['PET/P']\n",
    "    r_sm_qle = site_r_qle[site]['surf_sm']#.resample({'time': 'D'}).mean()\n",
    "    r_sm_qh = site_r_qh[site]['surf_sm']#.resample({'time': 'D'}).mean()\n",
    "    r_rh_qle = site_r_qle[site]['relhum']#.resample({'time': 'D'}).mean()\n",
    "    r_rh_qh = site_r_qh[site]['relhum']#.resample({'time': 'D'}).mean()\n",
    "    \n",
    "    r_sm_rh_qle.append(np.corrcoef(r_sm_qle, r_rh_qle)[0,1])\n",
    "    r_sm_rh_qh.append(np.corrcoef(r_sm_qh, r_rh_qh)[0,1])\n",
    "   \n",
    "    pvals.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "sm_rvals = []\n",
    "sw_rvals = []\n",
    "t_rvals = []\n",
    "rh_rvals = []\n",
    "for site in tqdm(sim_sites):\n",
    "    p = site_attrs.loc[site]['PET/P']\n",
    "    r_qle = site_r_qle[site]['surf_sm']#.resample({'time': 'W'}).mean()\n",
    "    r_qh = site_r_qh[site]['surf_sm']#.resample({'time': 'W'}).mean()\n",
    "    sm_rvals.append(np.corrcoef(r_qle, r_qh)[0,1])\n",
    "    r_qle = site_r_qle[site]['swradatm']#.resample({'time': 'W'}).mean()\n",
    "    r_qh = site_r_qh[site]['swradatm']#.resample({'time': 'W'}).mean()\n",
    "    sw_rvals.append(np.corrcoef(r_qle, r_qh)[0,1])\n",
    "                    \n",
    "    r_qle = site_r_qle[site]['airtemp']#.resample({'time': 'W'}).mean()\n",
    "    r_qh = site_r_qh[site]['airtemp']#.resample({'time': 'W'}).mean()\n",
    "    t_rvals.append(np.corrcoef(r_qle, r_qh)[0,1])\n",
    "    r_qle = site_r_qle[site]['relhum']#.resample({'time': 'W'}).mean()\n",
    "    r_qh = site_r_qh[site]['relhum']#.resample({'time': 'W'}).mean()\n",
    "    rh_rvals.append(np.corrcoef(r_qle, r_qh)[0,1])\n",
    "    pvals.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "t_rrat = []\n",
    "sw_rrat = []\n",
    "for site in sim_sites:\n",
    "    p = site_attrs.loc[site]['PET/P']\n",
    "                    \n",
    "    r_qle = site_r_qle[site]['airtemp'].resample({'time': 'D'}).mean()\n",
    "    r_qh = site_r_qh[site]['airtemp'].resample({'time': 'D'}).mean()\n",
    "    t_rrat.append(np.mean(r_qle)/np.mean(r_qh))\n",
    "    r_qle = site_r_qle[site]['swradatm'].resample({'time': 'D'}).mean()\n",
    "    r_qh = site_r_qh[site]['swradatm'].resample({'time': 'D'}).mean()\n",
    "    sw_rrat.append(np.mean(r_qle)/np.mean(r_qh))\n",
    "    pvals.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, dpi=150, sharex=True, figsize=(8, 12))\n",
    "axes[0].plot(pvals, sm_rvals, label='Surface moisture', linewidth=0, marker='o', color='tab:blue')\n",
    "#axes[0].set_xlabel('PET/P')\n",
    "axes[0].set_ylabel(r'Correlation($R_{SM\\rightarrow Q_{le}}, R_{SM\\rightarrow Q_{h}}$)')\n",
    "axes[0].axvline(1, linestyle='--', color='grey', zorder=-10)\n",
    "\n",
    "#axes[1].scatter(pvals, sw_rrat, marker='o', color='tab:blue')\n",
    "#axes[1].set_ylim([0, 1.8])\n",
    "#axes[1].set_xlabel('PET/P')\n",
    "#axes[1].set_ylabel(r'$\\frac{\\bar{R}_{SW\\rightarrow Q_{le}}}{\\bar{R}_{SW\\rightarrow Q_{h}}}$', fontsize=28)\n",
    "#axes[1].axvline(1, linestyle='--', color='grey', zorder=-10)\n",
    "\n",
    "axes[1].scatter(pvals, r_sm_rh_qle)\n",
    "axes[1].set_xlabel('PET/P')\n",
    "axes[1].set_ylabel(r'Correlation($R_{SM\\rightarrow Q_{le}}, R_{RH\\rightarrow Q_{le}}$)')\n",
    "axes[1].axvline(1, linestyle='--', color='grey', zorder=-10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_r_qle_df = {}\n",
    "mean_r_qh_df = {}\n",
    "normalize = True\n",
    "petp = site_attrs['PET/P'].sort_values().to_dict()\n",
    "for site in petp.keys():\n",
    "    avg_qle = site_ds[site]['scalarLatHeatTotal'].median(dim='time').values[()]\n",
    "    avg_qh = site_ds[site]['scalarSenHeatTotal'].median(dim='time').values[()]\n",
    "    mean_r_qle_df[site] = site_r_qle[site].to_dataframe().mean() \n",
    "    mean_r_qh_df[site] = site_r_qh[site].to_dataframe().mean() \n",
    "    if normalize:\n",
    "        mean_r_qle_df[site] /= np.sum(np.abs(mean_r_qle_df[site]))\n",
    "        mean_r_qh_df[site] /= np.sum(np.abs(mean_r_qh_df[site]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petp_idx = np.argmin(np.abs(np.array(list(petp.values())) - 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'airtemp': 'Temperature',\n",
    "               'relhum': 'Humidity',\n",
    "               'swradatm': 'Shortwave',\n",
    "               'surf_sm': 'Soil Moisture',\n",
    "               'lai': 'LAI',\n",
    "               'vegtype': 'Vegetation Type'\n",
    "              }\n",
    "mean_r_qle_df = {s: d.rename(rename_dict) for s, d in mean_r_qle_df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(18,10), sharex=True, sharey=True)\n",
    "\n",
    "pd.DataFrame(mean_r_qle_df).T.plot.bar(ax=axes[0], stacked=True, legend=False, width=0.7)\n",
    "pd.DataFrame(mean_r_qh_df).T.plot.bar(ax=axes[1], stacked=True, legend=False, width=0.7)\n",
    "axes[0].legend(ncol=7)\n",
    "axes[0].axhline(0, color='black', zorder=-10)\n",
    "axes[0].set_ylabel(r'Fraction of relevance to $Q_{le}$')\n",
    "axes[1].axhline(0, color='black', zorder=-10)\n",
    "axes[1].set_ylabel(r'Fraction of relevance to $Q_{h}$')\n",
    "axes[0].axvline(petp_idx+0.505, linestyle='--', color='dimgrey')\n",
    "axes[1].axvline(petp_idx+0.505, linestyle='--', color='dimgrey')\n",
    "axes[1].set_xlabel(r'Increasing PET/P $\\longrightarrow$')\n",
    "#axes[1].annotate('local max', xy=(30, -1.6),  xycoords='data',\n",
    "#            xytext=(10, -1.2), textcoords='data',\n",
    "#            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "#            horizontalalignment='right', verticalalignment='top',\n",
    "#            )\n",
    "plt.tight_layout()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = innvestigate.analyzer.LRPEpsilon(model, epsilon=1e-3, neuron_selection_mode='index')\n",
    "qle_analyzer = partial(analyzer.analyze, neuron_selection=0)\n",
    "qh_analyzer = partial(analyzer.analyze, neuron_selection=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_to_sm(new_input, surf_mults, qle_lrp, qh_lrp):\n",
    "    qle_mults = []\n",
    "    qh_mults = []\n",
    "    r_qle = []\n",
    "    r_qh = []\n",
    "    for sm in surf_mults:\n",
    "        modified_input = new_input.copy()\n",
    "        # Surface moisture\n",
    "        modified_input[:, 3] = sm\n",
    "           \n",
    "        qle_mults.append(500 * model.predict(modified_input)[0, 0].flatten())\n",
    "        qh_mults.append(500 * model.predict(modified_input)[0, 1].flatten())\n",
    "            \n",
    "        r_qle.append(qle_lrp(modified_input)[0, 3])\n",
    "        r_qh.append(qh_lrp(modified_input)[0, 3])\n",
    "        \n",
    "    qle_mults = np.array(qle_mults).flatten()\n",
    "    qh_mults = np.array(qh_mults).flatten()\n",
    "    r_qle = np.array(r_qle).flatten()\n",
    "    r_qh = np.array(r_qh).flatten()\n",
    "    qle = xr.DataArray(qle_mults, \n",
    "                   coords={'surface_moisture': surf_mults},\n",
    "                   dims=['surface_moisture'],\n",
    "                   name='Qle')\n",
    "    qh = xr.DataArray(qh_mults, \n",
    "                      coords={'surface_moisture': surf_mults}, \n",
    "                      dims=['surface_moisture'],\n",
    "                       name='Qh')\n",
    "    r_qle_sm = xr.DataArray(r_qle, \n",
    "                   coords={'surface_moisture': surf_mults},\n",
    "                   dims=['surface_moisture'],\n",
    "                   name='r_Qle_sm')\n",
    "    r_qh_sm = xr.DataArray(r_qh, \n",
    "                      coords={'surface_moisture': surf_mults},\n",
    "                      dims=['surface_moisture'],\n",
    "                       name='r_Qh_sm')\n",
    "    return xr.merge([qle, qh, r_qle_sm, r_qh_sm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharey='row')\n",
    "axes = axes.T.flatten()\n",
    "\n",
    "site = 'CH-Fru'\n",
    "var = 'airtemp'\n",
    "time_idx = np.argmin(np.abs(site_r_qle[site][var].values - site_r_qle[site][var].max().values[()]))\n",
    "new_input, new_output = format_data_for_nn(site_ds[site].isel(time=slice(time_idx-1, time_idx+1)), use_mask=False)\n",
    "\n",
    "sm_vals = np.arange(0, 1, 0.01)\n",
    "sm_ds = sensitivity_to_sm(new_input, sm_vals, qle_analyzer, qh_analyzer)\n",
    "sm_ds.assign_coords({'surface_moisture': sm_vals})\n",
    "\n",
    "axes[0].plot(sm_vals, sm_ds['Qle'], label='Latent heat')\n",
    "axes[0].plot(sm_vals, sm_ds['Qh'] , label='Sensible heat')\n",
    "axes[1].plot(sm_vals, sm_ds['r_Qle_sm'], label='Latent heat')\n",
    "axes[1].plot(sm_vals, sm_ds['r_Qh_sm'], label='Sensible heat')\n",
    "\n",
    "axes[0].set_title(site)\n",
    "site = 'US-Whs'\n",
    "time_idx = np.argmin(np.abs(site_r_qle[site][var].values - site_r_qle[site][var].max().values[()]))\n",
    "sm_vals = np.arange(0, 1, 0.01)\n",
    "\n",
    "new_input, new_output = format_data_for_nn(site_ds[site].isel(time=slice(time_idx, time_idx+1)), use_mask=False)\n",
    "sm_ds = sensitivity_to_sm(new_input, sm_vals, qle_analyzer, qh_analyzer)\n",
    "sm_ds.assign_coords({'surface_moisture': sm_vals})\n",
    "\n",
    "axes[2].plot(sm_vals, sm_ds['Qle']     , label='Latent heat')\n",
    "axes[2].plot(sm_vals, sm_ds['Qh']      , label='Sensible heat')\n",
    "axes[3].plot(sm_vals, sm_ds['r_Qle_sm'], label='Latent heat')\n",
    "axes[3].plot(sm_vals, sm_ds['r_Qh_sm'] , label='Sensible heat')\n",
    "axes[1].axhline(0, color='grey', linestyle='--')\n",
    "axes[3].axhline(0, color='grey', linestyle='--')\n",
    "axes[2].set_title(site)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel(r'Heat flux $(W/m^2)$')\n",
    "axes[1].set_ylabel('Relevance')\n",
    "axes[1].set_xlabel('Degree of saturation')\n",
    "axes[3].set_xlabel('Degree of saturation')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearizability_rel_qle = []\n",
    "linearizability_rel_qle_kge = []\n",
    "linearizability_rel_qh = []\n",
    "linearizability_rel_qh_kge = []\n",
    "linearizability_phys_qle = []\n",
    "linearizability_phys_qle_kge = []\n",
    "linearizability_phys_qh = []\n",
    "linearizability_phys_qh_kge = []\n",
    "\n",
    "for site in tqdm(sim_sites):\n",
    "    r_ds_qle = site_r_qle[site]\n",
    "    r_ds_qh = site_r_qh[site]\n",
    "    phys_ds = site_ds[site]\n",
    "    X = r_ds_qle.to_array().values.T\n",
    "    qle = phys_ds[['scalarLatHeatTotal']].to_array().values.T\n",
    "    qh = phys_ds[['scalarSenHeatTotal']].to_array().values.T\n",
    "    \n",
    "    rel_regr_qle = linear_model.LinearRegression()\n",
    "    rel_regr_qle.fit(X, qle)\n",
    "    qle_hat = rel_regr_qle.predict(X)\n",
    "    linearizability_rel_qle.append( rel_regr_qle.score(X, qle))\n",
    "    linearizability_rel_qle_kge.append(pse.kling_gupta_efficiency(qle_hat, qle))\n",
    "    \n",
    "    X = r_ds_qh.to_array().values.T\n",
    "    rel_regr_qh = linear_model.LinearRegression()\n",
    "    rel_regr_qh.fit(X, qh)\n",
    "    qh_hat = rel_regr_qh.predict(X)\n",
    "    linearizability_rel_qh.append( rel_regr_qh.score(X, qh))\n",
    "    linearizability_rel_qh_kge.append(pse.kling_gupta_efficiency(qh_hat, qh))\n",
    "\n",
    "    X = format_data_for_nn(phys_ds, use_mask=False)[0]\n",
    "    \n",
    "    phys_regr_qle = linear_model.LinearRegression()\n",
    "    phys_regr_qle.fit(X, qle)\n",
    "    qle_hat = phys_regr_qle.predict(X)\n",
    "    linearizability_phys_qle.append( phys_regr_qle.score(X, qle))\n",
    "    linearizability_phys_qle_kge.append(pse.kling_gupta_efficiency(qle_hat, qle))\n",
    "    \n",
    "    phys_regr_qh = linear_model.LinearRegression()\n",
    "    phys_regr_qh.fit(X, qh)\n",
    "    qh_hat = phys_regr_qh.predict(X)\n",
    "    linearizability_phys_qh.append( phys_regr_qh.score(X, qh))\n",
    "    linearizability_phys_qh_kge.append(pse.kling_gupta_efficiency(qh_hat, qh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([linearizability_rel_qle_kge, linearizability_rel_qh_kge]).T\n",
    "vplot = sns.violinplot(data=data, color='silver')\n",
    "\n",
    "plt.gca().get_children()[1].set_color('white')\n",
    "plt.gca().get_children()[3].set_color('white')\n",
    "plt.gca().get_children()[4].set_color('black')\n",
    "plt.gca().get_children()[5].set_color('black')\n",
    "plt.gca().get_children()[6].set_color('black')\n",
    "plt.gca().get_children()[7].set_color('black')\n",
    "plt.gca().get_children()[0].set_edgecolor(None)\n",
    "plt.gca().get_children()[2].set_edgecolor(None)\n",
    "plt.xticks(ticks=[0,1], labels=['Latent heat', 'Sensible heat'])\n",
    "plt.ylabel(r'KGE($Q_{NNLRP}, Q_{LM}$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_qle_kge = []\n",
    "linear_qh_kge = []\n",
    "full_qle_kge = []\n",
    "full_qh_kge = []\n",
    "\n",
    "\n",
    "for site in tqdm(sim_sites):\n",
    "    r_ds_qle = site_r_qle[site]\n",
    "    r_ds_qh = site_r_qh[site]\n",
    "    phys_ds = site_ds[site]\n",
    "    X = r_ds_qle.to_array().values.T\n",
    "    qle = phys_ds[['scalarLatHeatTotal']].to_array().values.T\n",
    "    qh = phys_ds[['scalarSenHeatTotal']].to_array().values.T\n",
    "    qle_obs = phys_ds[['Qle_cor']].to_array().values.T\n",
    "    qh_obs = phys_ds[['Qh_cor']].to_array().values.T\n",
    "    \n",
    "    rel_regr_qle = linear_model.LinearRegression()\n",
    "    rel_regr_qle.fit(X, qle)\n",
    "    qle_hat = rel_regr_qle.predict(X)\n",
    "    \n",
    "    X = r_ds_qh.to_array().values.T\n",
    "    rel_regr_qh = linear_model.LinearRegression()\n",
    "    rel_regr_qh.fit(X, qh)\n",
    "    qh_hat = rel_regr_qh.predict(X)\n",
    "\n",
    "    linear_qle_kge.append(pse.kling_gupta_efficiency(qle_hat, qle_obs))\n",
    "    full_qle_kge.append(pse.kling_gupta_efficiency(qle, qle_obs))\n",
    "    \n",
    "    phys_regr_qh = linear_model.LinearRegression()\n",
    "    phys_regr_qh.fit(X, qh)\n",
    "    qh_hat = phys_regr_qh.predict(X)\n",
    "    linearizability_phys_qh.append( phys_regr_qh.score(X, qh))\n",
    "    linearizability_phys_qh_kge.append(pse.kling_gupta_efficiency(qh_hat, qh))\n",
    "    \n",
    "    linear_qh_kge.append(pse.kling_gupta_efficiency(qh_hat, qh_obs))\n",
    "    full_qh_kge.append(pse.kling_gupta_efficiency(qh, qh_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsize = np.min([len(ds['time']) for ds in site_ds.values()])\n",
    "argmin  = np.argmin([len(ds['time']) for ds in site_ds.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_qle = np.nan * np.zeros((len(sim_sites), len(sim_sites)))\n",
    "similarity_qh  = np.nan * np.zeros((len(sim_sites), len(sim_sites)))\n",
    "similarity_mean = np.nan * np.zeros((len(sim_sites), len(sim_sites)))\n",
    "similarity_qle_kge = np.nan * np.zeros((len(sim_sites), len(sim_sites)))\n",
    "similarity_qh_kge = np.nan * np.zeros((len(sim_sites), len(sim_sites)))\n",
    "\n",
    "coef_qle = []\n",
    "coef_qh = []\n",
    "\n",
    "regr_vars = ['airtemp', 'relhum', 'swradatm', 'surf_sm', 'lai', 'vegtype']\n",
    "\n",
    "for i, site_a in tqdm(enumerate(sim_sites)):\n",
    "    r_ds_qle = site_r_qle[site_a]\n",
    "    r_ds_qh = site_r_qh[site_a]\n",
    "    phys_ds = site_ds[site_a]\n",
    "    \n",
    "    X_qle = r_ds_qle[regr_vars].to_array().values.T\n",
    "    X_qh = r_ds_qh[regr_vars].to_array().values.T\n",
    "    \n",
    "    #X_qle = format_data_for_nn(phys_ds, use_mask=False)[0]\n",
    "    #X_qh = format_data_for_nn(phys_ds, use_mask=False)[0]\n",
    "    \n",
    "    qle = phys_ds[['scalarLatHeatTotal']].to_array().values.T\n",
    "    qh = phys_ds[['scalarSenHeatTotal']].to_array().values.T\n",
    "   \n",
    "    # Trim to shortest length with random selection\n",
    "    sel_idxs = np.random.choice(np.arange(X_qle.shape[0]), size=minsize)\n",
    "    X_qle = X_qle[sel_idxs, :]\n",
    "    X_qh = X_qh[sel_idxs, :]\n",
    "    qle = qle[sel_idxs, :]\n",
    "    qh = qh[sel_idxs, :]\n",
    "\n",
    "    regr_qle = linear_model.LinearRegression()\n",
    "    regr_qle.fit(X_qle, qle)\n",
    "    coef_qle.append(np.hstack([regr_qle.intercept_, regr_qle.coef_.flatten()]))\n",
    "    \n",
    "    regr_qh = linear_model.LinearRegression()\n",
    "    regr_qh.fit(X_qh, qh)\n",
    "    coef_qh.append(np.hstack([regr_qh.intercept_, regr_qh.coef_.flatten()]))\n",
    " \n",
    "    for j, site_b in enumerate(sim_sites):\n",
    "        r_ds_qle = site_r_qle[site_b]\n",
    "        r_ds_qh = site_r_qh[site_b]\n",
    "        phys_ds = site_ds[site_b]\n",
    "        \n",
    "        X_qle = r_ds_qle[regr_vars].to_array().values.T\n",
    "        X_qh = r_ds_qh[regr_vars].to_array().values.T\n",
    "        #X_qle = format_data_for_nn(phys_ds, use_mask=False)[0]\n",
    "        #X_qh = format_data_for_nn(phys_ds, use_mask=False)[0]\n",
    "        \n",
    "        qle = phys_ds[['scalarLatHeatTotal']].to_array().values.T\n",
    "        qh = phys_ds[['scalarSenHeatTotal']].to_array().values.T\n",
    "        qle_hat = regr_qle.predict(X_qle)\n",
    "        qh_hat = regr_qh.predict(X_qh)\n",
    "   \n",
    "        similarity_qle_kge[i, j] = pse.kling_gupta_efficiency(qle_hat, qle)\n",
    "        similarity_qh_kge[i, j] = pse.kling_gupta_efficiency(qh_hat, qh)\n",
    "        similarity_qle[i, j] = np.max([0, regr_qle.score(X_qle, qle)])\n",
    "        similarity_qh[i, j] = np.max([0, regr_qh.score(X_qh, qh)])\n",
    "        similarity_mean[i, j] = np.max([0, 0.5 * (regr_qh.score(X_qh, qh) + regr_qle.score(X_qle, qle))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ds = xr.Dataset()\n",
    "similarity_ds['Qle'] = xr.DataArray(data=similarity_qle_kge, dims=['source', 'target'], coords={'source': sim_sites, 'target': sim_sites})\n",
    "similarity_ds['Qh'] = xr.DataArray(data=similarity_qh_kge, dims=['source', 'target'], coords={'source': sim_sites, 'target': sim_sites})\n",
    "similarity_ds['mean'] = 0.5 * (similarity_ds['Qle'] + similarity_ds['Qh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = ['intercept'] + regr_vars\n",
    "coef_ds = xr.Dataset()\n",
    "coef_ds['qle'] = xr.DataArray(data=coef_qle, dims=['site', 'coef'], coords={'site': sim_sites, 'coef': regrs})\n",
    "coef_ds['qh'] = xr.DataArray(data=coef_qh, dims=['site', 'coef'], coords={'site': sim_sites, 'coef': regrs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [\n",
    "          'orange', \n",
    "          'goldenrod', \n",
    "          'forestgreen',\n",
    "          'yellowgreen', \n",
    "          'lightgreen', \n",
    "          'khaki', \n",
    "          'mediumseagreen', \n",
    "          'chocolate', \n",
    "          'dodgerblue', \n",
    "          'firebrick', \n",
    "          'red',\n",
    "         ]\n",
    "veg_idxs = site_attrs['Veg Code'].unique().astype(int)-1\n",
    "cmp = LinearSegmentedColormap.from_list('veg', colors, N=len(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {v: c for v, c in zip(sorted(site_attrs['Veg Type'].unique()), colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,12))\n",
    "for s in similarity_ds.source.values:\n",
    "    c = color_mapping[site_attrs.loc[s]['Veg Type']]\n",
    "    plt.scatter((similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))),\n",
    "                (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))), \n",
    "                 color=c, s=250, marker='.', alpha=1)\n",
    "\n",
    "plt.axhline(-.17, color='dimgrey', linestyle='--')\n",
    "plt.axvline(-.17, color='dimgrey', linestyle='--')\n",
    "\n",
    "plt.gca().set_xlim([-1, 1])\n",
    "plt.gca().set_ylim([-1, 1])\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=v, markerfacecolor=c, markersize=12, )\n",
    "                   for v,c in color_mapping.items()]\n",
    "# Create the figure\n",
    "ax.legend(handles=legend_elements, fontsize=14, loc='lower left', frameon=False)\n",
    "ax.set_xlabel('Site performance as predictor ($KGE_m$)')\n",
    "ax.set_ylabel('Site performance as predictand ($KGE_m$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(21, 7), dpi=250, sharey=True)\n",
    "axes = axes.flatten()\n",
    "for s in similarity_ds.source.values:\n",
    "    c = color_mapping[site_attrs.loc[s]['Veg Type']]\n",
    "    xmed = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).median()\n",
    "    x_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).quantile(q=0.25)\n",
    "    x_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).quantile(q=0.75)\n",
    "    x2_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).quantile(q=0.35)\n",
    "    x2_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).quantile(q=0.65)\n",
    "    \n",
    "    ymed = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).median()\n",
    "    y_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).quantile(q=0.25)\n",
    "    y_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).quantile(q=0.75)\n",
    "    y2_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).quantile(q=0.35)\n",
    "    y2_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).quantile(q=0.65)\n",
    "    axes[0].plot([x_lo_iqr, x_hi_iqr], [ymed, ymed], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    axes[0].plot([xmed, xmed], [y_lo_iqr, y_hi_iqr], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    #plt.plot([x2_lo_iqr, x2_hi_iqr], [ymed, ymed], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    #plt.plot([xmed, xmed], [y2_lo_iqr, y2_hi_iqr], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    axes[0].scatter(xmed, ymed, color=c, s=400, marker='.', edgecolor='black', alpha=1, linewidth=1)\n",
    "\n",
    "axes[0].axhline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[0].axvline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[0].set_xlim([-1, 1])\n",
    "axes[0].set_ylim([-1, 1])\n",
    "\n",
    "enf = ['RU-Fyo', 'CA-Qfo', 'AU-ASM', 'US-Prr', 'IT-Ren', 'IT-Lav', 'US-GLE', 'IT-SRo', 'DE-Tha', 'FI-Let', 'CA-TP3', 'US-NR1', 'FI-Hyy', 'US-Blo', 'DE-Obe', 'FR-LBr', 'CA-TP1', 'FI-Sod', 'AU-Wac']\n",
    "for i, s in enumerate(enf):\n",
    "    c = color_mapping[site_attrs.loc[s]['Veg Type']]\n",
    "    xmed = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=enf).median()\n",
    "    x_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=enf).quantile(q=0.25)\n",
    "    x_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=enf).quantile(q=0.75)\n",
    "    x2_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=enf).quantile(q=0.35)\n",
    "    x2_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=enf).quantile(q=0.65)\n",
    "    \n",
    "    ymed = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=enf).median()\n",
    "    y_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=enf).quantile(q=0.25)\n",
    "    y_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=enf).quantile(q=0.75)\n",
    "    y2_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=enf).quantile(q=0.35)\n",
    "    y2_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=enf).quantile(q=0.65)\n",
    "    axes[2].plot([x_lo_iqr, x_hi_iqr], [ymed, ymed], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    axes[2].plot([xmed, xmed], [y_lo_iqr, y_hi_iqr], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    #plt.plot([x2_lo_iqr, x2_hi_iqr], [ymed, ymed], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    #plt.plot([xmed, xmed], [y2_lo_iqr, y2_hi_iqr], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    axes[2].scatter(xmed, ymed, color=c, s=400, marker='.', edgecolor='black', alpha=1, linewidth=1)\n",
    "    \n",
    "axes[1].axhline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[1].axvline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[1].set_xlim([-1, 1])\n",
    "axes[1].set_ylim([-1, 1])   \n",
    "\n",
    "nonenf = list(set(sim_sites) - set(enf))\n",
    "for i, s in enumerate(nonenf):\n",
    "    c = color_mapping[site_attrs.loc[s]['Veg Type']]\n",
    "    xmed = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=nonenf).median()\n",
    "    x_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=nonenf).quantile(q=0.25)\n",
    "    x_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=nonenf).quantile(q=0.75)\n",
    "    x2_lo_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=nonenf).quantile(q=0.35)\n",
    "    x2_hi_iqr = (similarity_ds['mean'].sel(source=s) / (2-similarity_ds['mean'].sel(source=s))).sel(target=nonenf).quantile(q=0.65)\n",
    "    \n",
    "    ymed = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=nonenf).median()\n",
    "    y_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=nonenf).quantile(q=0.25)\n",
    "    y_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=nonenf).quantile(q=0.75)\n",
    "    y2_lo_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=nonenf).quantile(q=0.35)\n",
    "    y2_hi_iqr = (similarity_ds['mean'].sel(target=s) / (2-similarity_ds['mean'].sel(target=s))).sel(source=nonenf).quantile(q=0.65)\n",
    "    axes[1].plot([x_lo_iqr, x_hi_iqr], [ymed, ymed], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    axes[1].plot([xmed, xmed], [y_lo_iqr, y_hi_iqr], color=c, linewidth=3, alpha=0.75, zorder=-1)\n",
    "    #plt.plot([x2_lo_iqr, x2_hi_iqr], [ymed, ymed], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    #plt.plot([xmed, xmed], [y2_lo_iqr, y2_hi_iqr], color=c, linewidth=8, alpha=0.5, zorder=-1)\n",
    "    axes[1].scatter(xmed, ymed, color=c, s=400, marker='.', edgecolor='black', alpha=1, linewidth=1)\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=v, markerfacecolor=c, markersize=12, )\n",
    "                   for v,c in color_mapping.items()]\n",
    "axes[2].legend(handles=legend_elements, fontsize=14, loc='lower left', frameon=True, framealpha=1)\n",
    "   \n",
    "    \n",
    "axes[2].axhline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[2].axvline(-.17, color='dimgrey', linestyle='--')\n",
    "axes[2].set_xlim([-1, 1])\n",
    "axes[2].set_ylim([-1, 1])   \n",
    "\n",
    "axes[0].set_xlabel('Site performance as predictor ($KGE_m$)')\n",
    "axes[0].set_ylabel('Site performance as predictand ($KGE_m$)')\n",
    "axes[1].set_xlabel('Site performance as predictor ($KGE_m$)')\n",
    "axes[2].set_xlabel('Site performance as predictor ($KGE_m$)')\n",
    "\n",
    "axes[0].set_title('All sites')\n",
    "axes[1].set_title('Purple cluster (non-evergreen)')\n",
    "axes[2].set_title('Green cluster (evergreen)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "cluster = sklearn.cluster.AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "cluster.fit(np.hstack([coef_qh, coef_qle]))\n",
    "km_labels_qh = cluster.labels_\n",
    "km_labels_qle = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(cluster_model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(cluster_model.children_.shape[0])\n",
    "    n_samples = len(cluster_model.labels_)\n",
    "    for i, merge in enumerate(cluster_model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([cluster_model.children_, cluster_model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "    #linkage_matrix[:, 2] = np.log(linkage_matrix[:, 2])\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    d = dendrogram(linkage_matrix, **kwargs)\n",
    "    return linkage_matrix, d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
